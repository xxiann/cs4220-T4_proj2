{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import umap\n",
    "import umap.plot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from matplotlib import rcParams\n",
    "plt.style.use(\"ggplot\")\n",
    "rcParams['figure.figsize'] = (12, 6)\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to look at the kmers available for each organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505536, 2080)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading training dataset\n",
    "with open('datasets/train.dataset.6mer.npy', 'rb') as open_file:\n",
    "    df = np.load(open_file)\n",
    "df = pd.DataFrame(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2071</th>\n",
       "      <th>2072</th>\n",
       "      <th>2073</th>\n",
       "      <th>2074</th>\n",
       "      <th>2075</th>\n",
       "      <th>2076</th>\n",
       "      <th>2077</th>\n",
       "      <th>2078</th>\n",
       "      <th>2079</th>\n",
       "      <th>genome_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2081 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \n",
       "0  0.002470  0.004528  0.003292  0.000823  0.003704  0.002880  0.001646  \\\n",
       "1  0.001818  0.002857  0.002077  0.001558  0.003635  0.002338  0.002338   \n",
       "2  0.003702  0.003084  0.001234  0.001851  0.002468  0.003084  0.003084   \n",
       "3  0.001102  0.002756  0.003584  0.001378  0.003307  0.002481  0.002481   \n",
       "4  0.004318  0.003534  0.002748  0.001701  0.003534  0.002356  0.002224   \n",
       "\n",
       "          7         8         9  ...      2071  2072  2073      2074   \n",
       "0  0.001646  0.001646  0.001646  ...  0.000000   0.0   0.0  0.000000  \\\n",
       "1  0.001039  0.001818  0.001039  ...  0.000519   0.0   0.0  0.000519   \n",
       "2  0.001851  0.001234  0.000617  ...  0.000000   0.0   0.0  0.000000   \n",
       "3  0.001102  0.001654  0.001378  ...  0.000000   0.0   0.0  0.000000   \n",
       "4  0.002617  0.003271  0.001440  ...  0.000000   0.0   0.0  0.000262   \n",
       "\n",
       "       2075  2076  2077  2078  2079  genome_label  \n",
       "0  0.000000   0.0   0.0   0.0   0.0            20  \n",
       "1  0.000260   0.0   0.0   0.0   0.0            20  \n",
       "2  0.000000   0.0   0.0   0.0   0.0            20  \n",
       "3  0.000000   0.0   0.0   0.0   0.0            20  \n",
       "4  0.000131   0.0   0.0   0.0   0.0            20  \n",
       "\n",
       "[5 rows x 2081 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the training labels\n",
    "df_y = pd.read_csv('datasets/train_labels.csv')\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_y['genome_name'].unique())\n",
    "labels = le.transform(df_y['genome_name'].values)\n",
    "\n",
    "df['genome_label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genome_name\n",
       "decoy                              446209\n",
       "burkholderia_pseudomallei            3787\n",
       "pseudomonas_aeruginosa               3342\n",
       "klebsiella_michiganensis             3167\n",
       "mycobacterium_ulcerans               2999\n",
       "klebsiella_pneumoniae                2840\n",
       "serratia_liquefaciens                2832\n",
       "citrobacter_freundii                 2718\n",
       "salmonella_enterica_typhimurium      2595\n",
       "salmonella_enterica_paratyphi        2579\n",
       "yersinia_enterocolitica              2416\n",
       "stenotrophomonas_maltophilia         2388\n",
       "mycobacterium_tuberculosis           2354\n",
       "clostridioides_difficile             2249\n",
       "acinetobacter_baumannii              2133\n",
       "legionella_pneumophila               1814\n",
       "vibrio_parahaemolyticus              1743\n",
       "listeria_monocytogenes               1588\n",
       "vibrio_cholerae                      1564\n",
       "staphylococcus_aureus                1493\n",
       "staphylococcus_pseudintermedius      1381\n",
       "corynebacterium_ulcerans             1306\n",
       "corynebacterium_diphtheriae          1274\n",
       "neisseria_meningitidis               1196\n",
       "streptococcus_equi                   1187\n",
       "neisseria_gonorrhoeae                1150\n",
       "streptococcus_pneumoniae             1142\n",
       "streptococcus_suis                   1137\n",
       "streptococcus_agalactiae             1098\n",
       "staphylococcus_pyogenes               945\n",
       "campylobacter_jejuni                  910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y['genome_name'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    505536.000000\n",
      "mean               NaN\n",
      "std           0.000000\n",
      "min           0.000000\n",
      "25%           0.975098\n",
      "50%           1.010742\n",
      "75%           1.039062\n",
      "max           1.311523\n",
      "dtype: float64\n",
      "22011\n",
      "(505536, 2081)\n",
      "(483525, 2081)\n"
     ]
    }
   ],
   "source": [
    "sum_row = df.iloc[:,:-1].sum(axis=1)\n",
    "print(sum_row.describe())\n",
    "print((sum_row < 0.9).sum())\n",
    "\n",
    "# to remove samples with low kmer count\n",
    "print(df.shape)\n",
    "df = df.loc[sum_row >= 0.9,:]\n",
    "print(df.shape)\n",
    "y_index = labels[sum_row >= 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nc(filename):\n",
    "    nc = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                header = line.strip().lstrip('>')\n",
    "                parts = header.split()\n",
    "                #print(parts)\n",
    "                if len(parts) >= 1:\n",
    "                    x = parts[1]\n",
    "                    x = x.split(',')[0]\n",
    "                    nc.append(x.split('.')[0])\n",
    "    return nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'datasets/train.dataset.raw.reads.fna'\n",
    "species = extract_nc(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 20, 20, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505536, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_name</th>\n",
       "      <th>rfseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staphylococcus_aureus</td>\n",
       "      <td>NC_007795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staphylococcus_aureus</td>\n",
       "      <td>NC_007795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>staphylococcus_aureus</td>\n",
       "      <td>NC_007795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>staphylococcus_aureus</td>\n",
       "      <td>NC_007795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staphylococcus_aureus</td>\n",
       "      <td>NC_007795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505531</th>\n",
       "      <td>decoy</td>\n",
       "      <td>NC_000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505532</th>\n",
       "      <td>decoy</td>\n",
       "      <td>NC_000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505533</th>\n",
       "      <td>decoy</td>\n",
       "      <td>NC_000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505534</th>\n",
       "      <td>decoy</td>\n",
       "      <td>NT_167249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505535</th>\n",
       "      <td>decoy</td>\n",
       "      <td>NC_000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  genome_name      rfseq\n",
       "0       staphylococcus_aureus  NC_007795\n",
       "1       staphylococcus_aureus  NC_007795\n",
       "2       staphylococcus_aureus  NC_007795\n",
       "3       staphylococcus_aureus  NC_007795\n",
       "4       staphylococcus_aureus  NC_007795\n",
       "...                       ...        ...\n",
       "505531                  decoy  NC_000004\n",
       "505532                  decoy  NC_000017\n",
       "505533                  decoy  NC_000011\n",
       "505534                  decoy  NT_167249\n",
       "505535                  decoy  NC_000002\n",
       "\n",
       "[505536 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labelling for the rfseq numbers\n",
    "\n",
    "sample_label = df_y.copy()\n",
    "sample_label['rfseq'] = species\n",
    "print(sample_label.shape)\n",
    "sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(x, frac=None, random=4):\n",
    "    \"\"\"\" subsampling certain fraction, unless when the species is only 1 \"\"\"\n",
    "    current = x.shape[0]\n",
    "    if current==1:\n",
    "        return x\n",
    "    x = x.sample(frac=frac, random_state=random)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([421679, 285281, 481246, 263189, 105081, 355473, 317703, 278399, 321451,\n",
       "       470007,\n",
       "       ...\n",
       "        14438,  14766,  14983,  14759,  14572,  14768,  14133,  14123,  15213,\n",
       "        14199],\n",
       "      dtype='int64', length=21248)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoy train set\n",
    "\n",
    "filt = sample_label.loc[sum_row >= 0.9,:]\n",
    "x = filt[filt['genome_name']=='decoy'].groupby('rfseq').apply(lambda x: sampling(x,0.05)).index.get_level_values(1) # index for selected decoys\n",
    "# x2 =sample_label[sample_label['genome_name']!='decoy'].index # index for all organisms\n",
    "# x = x.append(x2) # index for all selected samples\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21248, 2082)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genome_label'] = y_index\n",
    "df['rfseq'] = sample_label['rfseq']\n",
    "decoy = df.loc[x, :]\n",
    "decoy.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80385, 2080) (80385,)\n"
     ]
    }
   ],
   "source": [
    "X_red = pd.concat([df[df['genome_label']!=7].iloc[:,:-2], decoy.iloc[:,:-2]])\n",
    "y_red = pd.concat([df[df['genome_label']!=7]['genome_label'], decoy['genome_label']])\n",
    "print(X_red.shape, y_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4067185980955522\n",
      "0.3880290524925718\n"
     ]
    }
   ],
   "source": [
    "# percentage 0 - w/o removing\n",
    "print(sum(decoy[decoy == 0].iloc[:,:-2].count(axis=1))/(len(decoy.columns)*len(decoy.index)))\n",
    "\n",
    "X_red = pd.concat([df[df['genome_label']!=7].iloc[:,:-2], decoy.iloc[:,:-2]])\n",
    "print(sum(X_red[X_red == 0].count(axis=1))/(len(X_red.columns)*len(X_red.index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca(data, seed=4220, save=None):\n",
    "    \"\"\" Returns PCA & transformed data \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    import pickle as pkl\n",
    "    print(\"shape of data: \", data.shape)\n",
    "\n",
    "    new_pca = PCA(n_components=None, random_state=seed).fit(data)\n",
    "\n",
    "    lim = 0.9\n",
    "    ACC_VAR = 0\n",
    "    for i, var in enumerate(new_pca.explained_variance_ratio_):\n",
    "        ACC_VAR+=var\n",
    "        # print(var)\n",
    "        if ACC_VAR > lim: \n",
    "            print(f\"{i+1} components explained {lim}S of total var\")\n",
    "            break\n",
    "    \n",
    "    new_pca = PCA(n_components=i+1, random_state=seed) \n",
    "    data = new_pca.fit_transform(data)\n",
    "    print(new_pca)\n",
    "    print(\"shape of new data: \", data.shape)\n",
    "\n",
    "    if save!=None:\n",
    "        with open(save, 'wb') as pickle_file:\n",
    "            pkl.dump(new_pca, pickle_file)\n",
    "        print(\"model saved\")\n",
    "\n",
    "    return [new_pca, data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (80385, 2080)\n",
      "887 components explained 0.9S of total var\n",
      "PCA(n_components=887, random_state=4220)\n",
      "shape of new data:  (80385, 887)\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "new_pca, pca_data = create_pca(X_red, save='models/pca_ver1.2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8008002764091865\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=500, random_state=4220)\n",
    "svd_data = svd.fit_transform(X_red) # 0.8942969124131721 explained variance\n",
    "\n",
    "with open('svd_ver1.2.pkl', 'wb') as pickle_file:\n",
    "    pkl.dump(svd, pickle_file)\n",
    "\n",
    "\n",
    "lim = 0.9\n",
    "ACC_VAR = 0\n",
    "for i, var in enumerate(svd.explained_variance_ratio_):\n",
    "    ACC_VAR+=var\n",
    "    # print(var)\n",
    "    if ACC_VAR > lim: \n",
    "        print(f\"{i+1} components explained {lim}S of total var\")\n",
    "        break\n",
    "print(ACC_VAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4198, 2082)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoy test set\n",
    "x = filt[filt['genome_name']=='decoy'].groupby('rfseq').apply(lambda x: sampling(x,0.01,random=1)).index.get_level_values(1) # index for selected decoys\n",
    "\n",
    "decoy_test = df.loc[x, :]\n",
    "decoy_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = df[df['genome_label']!=7].iloc[:,:-1].groupby('genome_label').apply(lambda x: x.sample(910))\n",
    "# X_train,X_val,y_train,y_val = train_test_split(df[df['genome_label']!=7].iloc[:,:-2],df[df['genome_label']!=7]['genome_label'],random_state=4,test_size=0.2, stratify=df[df['genome_label']!=7]['genome_label'])\n",
    "X_train,X_val,y_train,y_val = train_test_split(df_train.iloc[:,:-1], df_train['genome_label'],random_state=4,test_size=0.2, stratify=df_train['genome_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43088, 2080) (43088,) (9658, 2080) (9658,)\n"
     ]
    }
   ],
   "source": [
    "# full set  + decoy\n",
    "X_train = pd.concat([X_train, decoy.iloc[:,:-2]])\n",
    "y_train = pd.concat([y_train, decoy['genome_label']])\n",
    "\n",
    "X_val = pd.concat([X_val, decoy_test.iloc[:,:-2]])\n",
    "y_val = pd.concat([y_val, decoy_test['genome_label']])\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.index.get_level_values(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tri_df= pd.read_csv('corr_matrix.csv', index_col=0) # created from running the full data\n",
    "# # to_drop = [c for c in tri_df.columns if any(tri_df[c] > 0.7)] # if column is labeled\n",
    "# to_drop = [c for c in range(len(tri_df.columns)) if any(tri_df[tri_df.columns[c]] > 0.7)] # if column is indexed\n",
    "# X_train.drop(columns=to_drop, inplace=True)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svm(x_data, y_label, save=None):\n",
    "    \"\"\" training support vector machine \"\"\"\n",
    "    from sklearn.svm import SVC\n",
    "    from joblib import dump\n",
    "    import timeit\n",
    "\n",
    "    print(\"training\")\n",
    "    starting_time = timeit.default_timer()\n",
    "\n",
    "    clf = SVC(kernel='rbf', probability=True)\n",
    "    clf.fit(x_data , y_label)\n",
    "    print(clf)\n",
    "\n",
    "    print(\"Time taken :\", timeit.default_timer() - starting_time)\n",
    "\n",
    "    if save != None:   \n",
    "        dump(clf, save) \n",
    "        print(\"model saved\")\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TruncatedSVD from version 1.1.3 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43088, 500) (43088,)\n"
     ]
    }
   ],
   "source": [
    "## prelim model running SVD\n",
    "# with open('svd_n500.pkl', 'rb') as pickle_file: # PCA embeddings trained on full data\n",
    "#     preprocess=pkl.load(pickle_file) \n",
    "\n",
    "\n",
    "# X_train = preprocess.transform(X_train)\n",
    "# print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "SVC(probability=True)\n",
      "Time taken : 2316.0964414000046\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "## prelim svd and corr matrix with downsampled training set\n",
    "# clf = create_svm(X_train, y_train, save='models/svm_prelim_ver1.2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43088, 2080) (43088,)\n",
      "training\n",
      "SVC(probability=True)\n",
      "Time taken : 1461.7157511999976\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "X_train = svd.transform(X_train)  # svd with downsampled 5% decoy\n",
    "clf = create_svm(X_train, y_train, save='models/svm_ver1.2.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_per_patient(patient_id, preds):\n",
    "    df_true = pd.read_csv('datasets/validation/patient{}_labels.txt'.format(patient_id))\n",
    "    tp,fp, tp_labels=0,0, df_true['true_label'].shape[0]\n",
    "    print('my prediction(s) for patient {}:'.format(patient_id))\n",
    "    print(preds)\n",
    "    print('true pathogen')\n",
    "    print(df_true['true_label'].values)\n",
    "    #if don't predict any pathogen, it means there is only decoy in the test dataset (your prediction)\n",
    "    if len(preds) == 0:\n",
    "        preds = ['decoy']\n",
    "    for item in np.unique(preds):\n",
    "        if item in df_true['true_label'].values:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    #you have to predict all labels correctly, but you are penalized for any false positive\n",
    "    return round(tp/(tp_labels+fp),5)\n",
    "\n",
    "\n",
    "\n",
    "#prediction for all patients\n",
    "def run_test(threshold=0.99, model=clf, preprocess=None):\n",
    "    all_precision = []\n",
    "    for patient_id in range(1,11):\n",
    "        print('predicting for patient {}'.format(patient_id))\n",
    "        \n",
    "        starting_time = timeit.default_timer()\n",
    "        with open('datasets/validation/patient{}.6mer.npy'.format(patient_id), 'rb') as read_file:\n",
    "            df_test = np.load(read_file)\n",
    "            df_test = pd.DataFrame(df_test)\n",
    "            \n",
    "        # df_test.drop(columns=to_drop, inplace=True) # for prelim model\n",
    "        df_test = preprocess.transform(df_test)\n",
    "        \n",
    "        y_predprob = model.predict_proba(df_test)\n",
    "        \n",
    "        #we get only predictions larger than the threshold and if there is more than one, we take the argmax again\n",
    "        final_predictions = le.inverse_transform(np.unique([np.argmax(item) for item in y_predprob  if len(np.where(item>= threshold)[0]) >=1]\n",
    "                                                    ))\n",
    "        #my pathogens dectected, decoy will be ignored\n",
    "        final_predictions = [item for item in final_predictions if item !='decoy']\n",
    "        \n",
    "        precision = precision_per_patient(patient_id, final_predictions)\n",
    "        print('precision: {}'.format(precision))\n",
    "        all_precision.append(precision)\n",
    "        print(\"Time taken :\", timeit.default_timer() - starting_time)\n",
    "    # performance per patient and its final average\n",
    "    print([f'patient {c}: {item}' for c, item in enumerate(all_precision, start=1)])\n",
    "    print(f'avg: {np.mean(all_precision)}')\n",
    "    return round(np.mean(all_precision), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting for patient 1\n",
      "my prediction(s) for patient 1:\n",
      "['staphylococcus_aureus']\n",
      "true pathogen\n",
      "['staphylococcus_aureus']\n",
      "precision: 1.0\n",
      "Time taken : 138.59140799999295\n",
      "predicting for patient 2\n",
      "my prediction(s) for patient 2:\n",
      "['burkholderia_pseudomallei', 'staphylococcus_aureus', 'staphylococcus_pyogenes']\n",
      "true pathogen\n",
      "['staphylococcus_pyogenes']\n",
      "precision: 0.33333\n",
      "Time taken : 144.5654641000001\n",
      "predicting for patient 3\n",
      "my prediction(s) for patient 3:\n",
      "['burkholderia_pseudomallei', 'corynebacterium_ulcerans']\n",
      "true pathogen\n",
      "['burkholderia_pseudomallei' 'corynebacterium_ulcerans']\n",
      "precision: 1.0\n",
      "Time taken : 146.0772649999999\n",
      "predicting for patient 4\n",
      "my prediction(s) for patient 4:\n",
      "['pseudomonas_aeruginosa']\n",
      "true pathogen\n",
      "['pseudomonas_aeruginosa']\n",
      "precision: 1.0\n",
      "Time taken : 114.68902330000128\n",
      "predicting for patient 5\n",
      "my prediction(s) for patient 5:\n",
      "['corynebacterium_diphtheriae', 'corynebacterium_ulcerans']\n",
      "true pathogen\n",
      "['corynebacterium_diphtheriae']\n",
      "precision: 0.5\n",
      "Time taken : 140.5064640000055\n",
      "predicting for patient 6\n",
      "my prediction(s) for patient 6:\n",
      "['streptococcus_pneumoniae']\n",
      "true pathogen\n",
      "['streptococcus_pneumoniae']\n",
      "precision: 1.0\n",
      "Time taken : 139.2566141999996\n",
      "predicting for patient 7\n",
      "my prediction(s) for patient 7:\n",
      "['mycobacterium_tuberculosis', 'mycobacterium_ulcerans']\n",
      "true pathogen\n",
      "['mycobacterium_ulcerans']\n",
      "precision: 0.5\n",
      "Time taken : 142.44454759999644\n",
      "predicting for patient 8\n",
      "my prediction(s) for patient 8:\n",
      "['streptococcus_pneumoniae']\n",
      "true pathogen\n",
      "['mycobacterium_tuberculosis' 'streptococcus_pneumoniae']\n",
      "precision: 0.5\n",
      "Time taken : 137.0500716999959\n",
      "predicting for patient 9\n",
      "my prediction(s) for patient 9:\n",
      "['streptococcus_pneumoniae']\n",
      "true pathogen\n",
      "['streptococcus_pneumoniae']\n",
      "precision: 1.0\n",
      "Time taken : 131.31719750000047\n",
      "predicting for patient 10\n",
      "my prediction(s) for patient 10:\n",
      "['burkholderia_pseudomallei']\n",
      "true pathogen\n",
      "['burkholderia_pseudomallei']\n",
      "precision: 1.0\n",
      "Time taken : 147.23884650001128\n",
      "['patient 1: 1.0', 'patient 2: 0.33333', 'patient 3: 1.0', 'patient 4: 1.0', 'patient 5: 0.5', 'patient 6: 1.0', 'patient 7: 0.5', 'patient 8: 0.5', 'patient 9: 1.0', 'patient 10: 1.0']\n",
      "avg: 0.7833330000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new model \n",
    "run_test(model=clf, preprocess=svd, threshold=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting for patient 1\n",
      "my prediction(s) for patient 1:\n",
      "[]\n",
      "true pathogen\n",
      "['staphylococcus_aureus']\n",
      "precision: 0.0\n",
      "Time taken : 149.9431970000005\n",
      "predicting for patient 2\n",
      "my prediction(s) for patient 2:\n",
      "['staphylococcus_pyogenes']\n",
      "true pathogen\n",
      "['staphylococcus_pyogenes']\n",
      "precision: 1.0\n",
      "Time taken : 147.58025810000254\n",
      "predicting for patient 3\n"
     ]
    }
   ],
   "source": [
    "# new model \n",
    "run_test(model=clf, preprocess=svd, threshold=0.995)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prelim model with new training set (thres: 0.99) - might be .95 dont rmb\n",
    "``` predicting for patient 1\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 1:\n",
    "['staphylococcus_aureus']\n",
    "true pathogen\n",
    "['staphylococcus_aureus']\n",
    "precision: 1.0\n",
    "Time taken : 211.64389069999743\n",
    "predicting for patient 2\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 2:\n",
    "['staphylococcus_pyogenes']\n",
    "true pathogen\n",
    "['staphylococcus_pyogenes']\n",
    "precision: 1.0\n",
    "Time taken : 217.85566260000633\n",
    "predicting for patient 3\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 3:\n",
    "['burkholderia_pseudomallei', 'corynebacterium_ulcerans']\n",
    "true pathogen\n",
    "['burkholderia_pseudomallei' 'corynebacterium_ulcerans']\n",
    "precision: 1.0\n",
    "Time taken : 209.61945990000095\n",
    "predicting for patient 4\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 4:\n",
    "['pseudomonas_aeruginosa']\n",
    "true pathogen\n",
    "['pseudomonas_aeruginosa']\n",
    "precision: 1.0\n",
    "Time taken : 214.08469499999774\n",
    "predicting for patient 5\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 5:\n",
    "['corynebacterium_diphtheriae', 'corynebacterium_ulcerans']\n",
    "true pathogen\n",
    "['corynebacterium_diphtheriae']\n",
    "precision: 0.5\n",
    "Time taken : 206.45827980000468\n",
    "predicting for patient 6\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 6:\n",
    "['streptococcus_pneumoniae']\n",
    "true pathogen\n",
    "['streptococcus_pneumoniae']\n",
    "precision: 1.0\n",
    "Time taken : 214.49726079999527\n",
    "predicting for patient 7\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 7:\n",
    "['mycobacterium_tuberculosis', 'mycobacterium_ulcerans']\n",
    "true pathogen\n",
    "['mycobacterium_ulcerans']\n",
    "precision: 0.5\n",
    "Time taken : 219.3507050999906\n",
    "predicting for patient 8\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 8:\n",
    "['streptococcus_pneumoniae']\n",
    "true pathogen\n",
    "['mycobacterium_tuberculosis' 'streptococcus_pneumoniae']\n",
    "precision: 0.5\n",
    "Time taken : 206.25283109999145\n",
    "predicting for patient 9\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 9:\n",
    "['streptococcus_pneumoniae']\n",
    "true pathogen\n",
    "['streptococcus_pneumoniae']\n",
    "precision: 1.0\n",
    "Time taken : 215.84426240000175\n",
    "predicting for patient 10\n",
    "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
    "  warnings.warn(\n",
    "my prediction(s) for patient 10:\n",
    "['burkholderia_pseudomallei']\n",
    "true pathogen\n",
    "['burkholderia_pseudomallei']\n",
    "precision: 1.0\n",
    "Time taken : 220.01919639999687\n",
    "['patient 1: 1.0', 'patient 2: 1.0', 'patient 3: 1.0', 'patient 4: 1.0', 'patient 5: 0.5', 'patient 6: 1.0', 'patient 7: 0.5', 'patient 8: 0.5', 'patient 9: 1.0', 'patient 10: 1.0']\n",
    "avg: 0.85 ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing (prelim model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_per_patient(patient_id, preds):\n",
    "    df_true = pd.read_csv('datasets/validation/patient{}_labels.txt'.format(patient_id))\n",
    "    tp,fp, tp_labels=0,0, df_true['true_label'].shape[0]\n",
    "    print('my prediction(s) for patient {}:'.format(patient_id))\n",
    "    print(preds)\n",
    "    print('true pathogen')\n",
    "    print(df_true['true_label'].values)\n",
    "    #if don't predict any pathogen, it means there is only decoy in the test dataset (your prediction)\n",
    "    if len(preds) == 0:\n",
    "        preds = ['decoy']\n",
    "    for item in np.unique(preds):\n",
    "        if item in df_true['true_label'].values:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    #you have to predict all labels correctly, but you are penalized for any false positive\n",
    "    return round(tp/(tp_labels+fp),5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snippet to load the grouth truth training labels and normalize the label predictions. \n",
    "#your trained model will predict in this space (0 to 10)\n",
    "df_y = pd.read_csv('datasets/train_labels.csv')\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_y['genome_name'].unique())\n",
    "\n",
    "## dropping highly corr column\n",
    "tri_df= pd.read_csv('corr_matrix.csv', index_col=0)\n",
    "to_drop = [c for c in range(len(tri_df.columns)) if any(tri_df[tri_df.columns[c]] > 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "#load trained model\n",
    "clf = load('svm_svdfull_910.joblib')\n",
    "\n",
    "with open('svd_n500.pkl', 'rb') as pickle_file: # PCA embeddings trained on full data\n",
    "    preprocess=pkl.load(pickle_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting for patient 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 1:\n",
      "['listeria_monocytogenes', 'staphylococcus_aureus']\n",
      "true pathogen\n",
      "['staphylococcus_aureus']\n",
      "precision: 0.5\n",
      "Time taken : 197.43884419999085\n",
      "predicting for patient 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 2:\n",
      "['listeria_monocytogenes', 'staphylococcus_aureus', 'staphylococcus_pyogenes']\n",
      "true pathogen\n",
      "['staphylococcus_pyogenes']\n",
      "precision: 0.33333\n",
      "Time taken : 174.24373459999333\n",
      "predicting for patient 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 3:\n",
      "['burkholderia_pseudomallei', 'corynebacterium_ulcerans', 'listeria_monocytogenes', 'staphylococcus_aureus']\n",
      "true pathogen\n",
      "['burkholderia_pseudomallei' 'corynebacterium_ulcerans']\n",
      "precision: 0.5\n",
      "Time taken : 160.4835132000153\n",
      "predicting for patient 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 4:\n",
      "['listeria_monocytogenes', 'pseudomonas_aeruginosa', 'staphylococcus_aureus']\n",
      "true pathogen\n",
      "['pseudomonas_aeruginosa']\n",
      "precision: 0.33333\n",
      "Time taken : 156.60702299998957\n",
      "predicting for patient 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 5:\n",
      "['corynebacterium_diphtheriae', 'corynebacterium_ulcerans', 'listeria_monocytogenes']\n",
      "true pathogen\n",
      "['corynebacterium_diphtheriae']\n",
      "precision: 0.33333\n",
      "Time taken : 156.52495269998326\n",
      "predicting for patient 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 6:\n",
      "['streptococcus_pneumoniae']\n",
      "true pathogen\n",
      "['streptococcus_pneumoniae']\n",
      "precision: 1.0\n",
      "Time taken : 191.80242230001022\n",
      "predicting for patient 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 7:\n",
      "['mycobacterium_tuberculosis', 'mycobacterium_ulcerans']\n",
      "true pathogen\n",
      "['mycobacterium_ulcerans']\n",
      "precision: 0.5\n",
      "Time taken : 155.87797979998868\n",
      "predicting for patient 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 8:\n",
      "['mycobacterium_tuberculosis', 'streptococcus_pneumoniae']\n",
      "true pathogen\n",
      "['mycobacterium_tuberculosis' 'streptococcus_pneumoniae']\n",
      "precision: 1.0\n",
      "Time taken : 158.9368245000078\n",
      "predicting for patient 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 9:\n",
      "['listeria_monocytogenes', 'staphylococcus_aureus', 'streptococcus_pneumoniae']\n",
      "true pathogen\n",
      "['streptococcus_pneumoniae']\n",
      "precision: 0.33333\n",
      "Time taken : 176.23887879998074\n",
      "predicting for patient 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaox\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but TruncatedSVD was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction(s) for patient 10:\n",
      "['burkholderia_pseudomallei', 'listeria_monocytogenes', 'staphylococcus_aureus']\n",
      "true pathogen\n",
      "['burkholderia_pseudomallei']\n",
      "precision: 0.33333\n",
      "Time taken : 168.83315320001566\n",
      "['patient 1: 0.5', 'patient 2: 0.33333', 'patient 3: 0.5', 'patient 4: 0.33333', 'patient 5: 0.33333', 'patient 6: 1.0', 'patient 7: 0.5', 'patient 8: 1.0', 'patient 9: 0.33333', 'patient 10: 0.33333']\n",
      "avg: 0.516665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction for all patients\n",
    "def run_test(threshold=0.99, model=clf, preprocess=None):\n",
    "    all_precision = []\n",
    "    for patient_id in range(1,11):\n",
    "        print('predicting for patient {}'.format(patient_id))\n",
    "        \n",
    "        starting_time = timeit.default_timer()\n",
    "        with open('datasets/validation/patient{}.6mer.npy'.format(patient_id), 'rb') as read_file:\n",
    "            df_test = np.load(read_file)\n",
    "            df_test = pd.DataFrame(df_test)\n",
    "            \n",
    "        df_test.drop(columns=to_drop, inplace=True)\n",
    "        df_test = preprocess.transform(df_test)\n",
    "        \n",
    "        y_predprob = model.predict_proba(df_test)\n",
    "        \n",
    "        #we get only predictions larger than the threshold and if there is more than one, we take the argmax again\n",
    "        final_predictions = le.inverse_transform(np.unique([np.argmax(item) for item in y_predprob  if len(np.where(item>= threshold)[0]) >=1]\n",
    "                                                    ))\n",
    "        #my pathogens dectected, decoy will be ignored\n",
    "        final_predictions = [item for item in final_predictions if item !='decoy']\n",
    "        \n",
    "        precision = precision_per_patient(patient_id, final_predictions)\n",
    "        print('precision: {}'.format(precision))\n",
    "        all_precision.append(precision)\n",
    "        print(\"Time taken :\", timeit.default_timer() - starting_time)\n",
    "    # performance per patient and its final average\n",
    "    print([f'patient {c}: {item}' for c, item in enumerate(all_precision, start=1)])\n",
    "    print(f'avg: {np.mean(all_precision)}')\n",
    "    return round(np.mean(all_precision), 5)\n",
    "\n",
    "run_test(model=clf, preprocess=preprocess, threshold=0.99)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
